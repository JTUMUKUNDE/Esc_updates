{"cells":[{"cell_type":"markdown","metadata":{"id":"_5zwEZiibULP"},"source":["<img src=\"https://tinyurl.com/k2t79s6t\" style=\"float: left; margin: 20px; height: 55px\">\n"," \n","# Basic Elementary Exploratory Data Analysis using Pandas\n","\n","_Author: Christopher Chan_"]},{"cell_type":"markdown","metadata":{"id":"9S9d7bWXbULY"},"source":["### Objective\n","\n","Upon completion of this lesson you should be able to understand the following:\n","\n","1. Pandas library\n","2. Dataframes\n","3. Data selection\n","4. Data manipulation\n","5. Handling of missing data\n","\n","This is arguably the most important part of analysis. This is also referred to as the \"cleaning the data\". Data must be usable for it to a valid analysis. Otherwise it would be garbage in, garbage out."]},{"cell_type":"markdown","metadata":{"id":"t4dPMZL1bULZ"},"source":["##### ==================================================================================================\n","## Data Selection and Inspection\n","\n","\n","### Pandas Library\n","\n","`pandas` is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n","built on top of the Python programming language.\n","\n","`pandas` data frame can be created by loading the data from the external, existing storage like a database, SQL, or CSV files. But the Pandas Data Frame can also be created from the lists, dictionary, etc. For simplicity, we will use `.csv` files. One of the ways to create a pandas data frame is shown below:\n","\n","### DataFrames\n","A data frame is a structured representation of data.\n","##### ==================================================================================================\n","We will first manually construct a `dictionary` that include the name, age and salary of people."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEtUwOCAbULb"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEzp1HBCbULd"},"outputs":[],"source":["data = {'Name':['John', 'Tiffany', 'Chris', 'Wesley', 'Daniel'],\n","        'Age': [24, 23, 22, 19, 10], \n","        'Salary': [60000,120000,1000000,75000,80000]}\n","\n","people_df = pd.DataFrame(data)"]},{"cell_type":"markdown","metadata":{"id":"LeP-DtdHbULe"},"source":["##### ==================================================================================================\n","We can call on the dataframe we labeled `people_df` by applying the `.head()` function that would display the first five rows of the dataframe. Similarly, the `.tail()` function would return the last five rows of a dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SQEwKWJbULf"},"outputs":[],"source":["people_df.head()"]},{"cell_type":"markdown","metadata":{"id":"5TDR_pKlbULg"},"source":["##### ==================================================================================================\n","We can also modify the number of rows we would like to display by inserting the integer into the `.head()` function.\n","\n","Example: Select the first 2 rows of the dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"myq2wwt4bULh"},"outputs":[],"source":["people_df.head(2)"]},{"cell_type":"markdown","metadata":{"id":"GnnaZo-qbULi"},"source":["##### ==================================================================================================\n","Another way would be to load an existing CSV file by using the `read_csv` function built into `pandas` onto the desired file path as shown below:\n","\n","`dataframe = pd.read_csv(\"C:/file_location/file_name.csv\")`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQ4TqrRrbULj"},"outputs":[],"source":["movies_df = pd.read_csv(\"Pixar_Movies.csv\")"]},{"cell_type":"markdown","metadata":{"id":"HjXzb3GObULj"},"source":["##### ==================================================================================================\n","We can view first 10 rows of the dataframe we just loaded in by using the `.head()` function with 10 as the parameter. (parameter of -1 would display all rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FtjsvleFbULk"},"outputs":[],"source":["movies_df.head(10)"]},{"cell_type":"markdown","metadata":{"id":"DLLQa7vmbULk"},"source":["#### The above python code is equivalent to SQL's\n","\n","```sql\n","SELECT * \n","FROM Movies\n","LIMIT 10\n","```\n","##### =================================================================================================="]},{"cell_type":"markdown","metadata":{"id":"JCgPu5lGbULl"},"source":["`.shape` shows the number of rows and columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jtfL13-bULl"},"outputs":[],"source":["movies_df.shape"]},{"cell_type":"markdown","metadata":{"id":"EVYGkXzrbULm"},"source":["This shows us how many rows and columns are in the entire dataframe, 14 rows, 5 columns\n","\n","##### =================================================================================================="]},{"cell_type":"markdown","metadata":{"id":"IMaAmpxCbULn"},"source":["`.dtypes` shows the data types"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"td0QBa_UbULo"},"outputs":[],"source":["movies_df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"wXAyu0-qbULo"},"source":["##### ==================================================================================================\n","`.describe()` generates descriptive statistics that include the count, mean (average), standard deviation, minimum, maximum and percentiles (by default returns 25th, 50th and 75th percentiles). Not to be confused with quantiles which are given as decimal values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tb96Pt3vbULp"},"outputs":[],"source":["movies_df.describe()"]},{"cell_type":"markdown","metadata":{"id":"o0AUAeV5bULp"},"source":["##### ==================================================================================================\n","`.info()` prints us a concise summary of a DataFrame that includes information about the index dtype and columns, non-null values and memory usage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vPBPx_J4bULp"},"outputs":[],"source":["movies_df.info()"]},{"cell_type":"markdown","metadata":{"id":"-qald4V-bULq"},"source":["##### ==================================================================================================\n","\n","### Row and Column Selection\n","\n","There are two common ways to select rows and columns in a dataframe using .loc and .iloc\n","\n","`.loc` selects rows and columns by label/name\n","\n","`.iloc` selects row and columns by index\n","\n","Example: using `.loc` to select every row in the dataframe by using `:` and filtering the column to just first_name, last_name and phone"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHAnMif2bULr"},"outputs":[],"source":["movies_df.loc[:,['Title','Director','Year']]"]},{"cell_type":"markdown","metadata":{"id":"W92l92XFbULr"},"source":["##### ==================================================================================================\n","\n","Similarly we obtain the same results using `.iloc` by filtering the columns to the 1, 2, and 3 column that correspond to as Title, Director and Year respectively as shown below:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxqV7Tx9bULr"},"outputs":[],"source":["movies_df.iloc[:,[1,2,3]]"]},{"cell_type":"markdown","metadata":{"id":"zoqJ2C1rbULs"},"source":["#### The two python codes above are equivalent to SQL's\n","\n","```sql\n","SELECT Title, Director, Year\n","FROM Movies\n","```\n","\n","##### ==================================================================================================\n","We can also control which rows we would like to view by slicing the rows. As an example we would like to show only the first 3 rows."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sw8gzGmkbULs"},"outputs":[],"source":["movies_df.iloc[0:3,[1,2,3]]"]},{"cell_type":"markdown","metadata":{"id":"9K3kh2RFbULt"},"source":["#### The above python code is equivalent to SQL's\n","\n","```sql\n","SELECT Title, Director, Year\n","FROM Movies\n","LIMIT 3\n","```\n","##### ==================================================================================================\n","Similary, we can show the first 3 rows after a specified row by offsetting our starting point. \n","\n","Generally the syntax follows: `dataframe.iloc[start:end],[col_num1, col_num2]]`. This is the same for `.loc`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPt1pWHMbULt"},"outputs":[],"source":["movies_df.iloc[2:5,[1,2,3]]"]},{"cell_type":"markdown","metadata":{"id":"bLiBtdiAbULu"},"source":["#### The above python code is equivalent to SQL's\n","\n","```sql\n","SELECT * \n","FROM movies\n","LIMIT 3\n","OFFSET 2\n","```\n","##### ==================================================================================================\n","`.value_counts()` returns the count of unique values (excluding NA values by default). "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpZyHGYCbULu"},"outputs":[],"source":["movies_df.loc[:,'Director'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"yuE5warKbULu"},"source":["#### The above python code is equivalent to SQL's\n","```sql\n","SELECT Director, COUNT(*)\n","FROM Movies\n","GROUP BY Director\n","```\n","##### ==================================================================================================\n","### Filtering Data\n","Using operator comparisons on columns returns information based on our desired conditions\n","\n","Example: Suppose we want to return movie information if it is only longer than 100 minutes long."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LURpbMgbULv"},"outputs":[],"source":["movies_df.loc[movies_df.loc[:, \"Length_minutes\"] > 100, :]"]},{"cell_type":"markdown","metadata":{"id":"X9xfZojrbULv"},"source":["#### The above python code is equivalent to SQL's\n","```sql\n","SELECT *\n","FROM Movies\n","WHERE Length_minutes > 100\n","```\n","##### ==================================================================================================\n","\n","#### Multiple Conditional Filtering\n","\n","Supposed we want to return movie information only if it is longer than 100 minutes and was created before the year 2005"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EQ3iyhqebULv"},"outputs":[],"source":["movies_df.loc[(movies_df.loc[:, \"Length_minutes\"] > 100) & (movies_df.loc[:, \"Year\"] < 2005), :]"]},{"cell_type":"markdown","metadata":{"id":"HZd4N0pZbULw"},"source":["#### The above python code is equivalent to SQL's\n","```sql\n","SELECT *\n","FROM Movies\n","WHERE Length_minutes > 100\n","AND Year < 2005\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"dxwan2S8bULw"},"source":["##### ==================================================================================================\n","### Sorting Data\n","The `sort_values()` method sorts the list ascending by default. To sort by descending order, you must apply `ascending = False`. \n","\n","The `.reset_index(drop=True)` will re-index the index after sorting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7866IBKybULw"},"outputs":[],"source":["movies_df.loc[:,\"Title\"].sort_values().reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"GmOw6asYbULw"},"source":["#### The above python code is equivalent to SQL's\n","\n","```sql\n","SELECT Title\n","FROM Movies\n","ORDER BY Title\n","```\n","##### ==================================================================================================\n","\n","Sort the entire dataframe by a single column:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9iWxtqCbULw"},"outputs":[],"source":["movies_df.sort_values(\"Title\").reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"TJUQeLJpbULx"},"source":["#### The above python code is equivalent to SQL's\n","```sql\n","SELECT *\n","FROM Movies\n","ORDER BY Title\n","```\n","##### ==================================================================================================\n","\n","We can also sort using multiple columns.\n","Example: We can sort by Director first, then within each Director, sort the Title of the films."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvLhcSbXbULx"},"outputs":[],"source":["movies_df.sort_values([\"Director\",\"Title\"],ascending=[True, True]).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"fvw5ekCebULy"},"source":["##### ==================================================================================================\n","### Merging DataFrames\n","\n","In python the `.concat` function combines dataframes together. This can be either one on top of another dataframe or side by side.\n","\n","But first let us introduce a new dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kdXxZxpTbULy"},"outputs":[],"source":["other_movies_df = pd.read_csv(\"Other_Movies.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fi5xbLtUbULy"},"outputs":[],"source":["other_movies_df.head()"]},{"cell_type":"markdown","metadata":{"id":"QM2wxWDYbULz"},"source":["##### ==================================================================================================\n","Now lets combine the two dataframes, that being `movies_df` and `other_movies_df` using the `.concat` function and call this new dataframe `all_movies_df`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"php4INt6bULz"},"outputs":[],"source":["all_movies_df = pd.concat([movies_df,other_movies_df]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHy-BncebULz"},"outputs":[],"source":["all_movies_df.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"MCc1n-olbULz"},"source":["##### ==================================================================================================\n","Now lets introduce another dataframe, that being the movie scores received"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7zwCWoZQbUL0"},"outputs":[],"source":["scores_df = pd.read_csv(\"Movie_Scores.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Py_YmBg5bUL0"},"outputs":[],"source":["scores_df.head(20)"]},{"cell_type":"markdown","metadata":{"id":"nKpeYohabUL1"},"source":["##### ==================================================================================================\n","Now we can combine the two dataframes side by side"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bp5YM6ZtbUL1"},"outputs":[],"source":["movies_and_scores_df = pd.concat([all_movies_df,scores_df], axis = \"columns\").reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1Ffi2UbbUL1"},"outputs":[],"source":["movies_and_scores_df.head(20)"]},{"cell_type":"markdown","metadata":{"id":"t_Dx465ObUL2"},"source":["##### ==================================================================================================\n","\n","We will define two new dataframes called `managers` and `captains`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHzrox_0bUL2"},"outputs":[],"source":["managers = pd.DataFrame(\n","    {\n","    'Id': [1,2,3],\n","    'Manager':['Chris','Maritza','Jamin']\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuZyLGNMbUL2"},"outputs":[],"source":["managers.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIq8T2CNbUL2"},"outputs":[],"source":["captains = pd.DataFrame(\n","    {\n","    'Id': [2,2,3,1,1,3,2,3,1,1,3,3],\n","    'Captain':['Richard','Goku','Martin','Winnie','Sammy','Joseph','Tim','Kaiden','Saitama','Angelina','Vegeta','Carl'],\n","    'Title':['C','C','SC','C','SC','C','EC','SC','C','EC','C','SC']\n","    }\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A9GUYIf3bUL3"},"outputs":[],"source":["captains.head(12)"]},{"cell_type":"markdown","metadata":{"id":"aw4_H0pBbUL3"},"source":["##### ==================================================================================================\n","We will now merge the two dataframes by using the `merge()` function. \n","\n","General syntax: `dataframe1.merge(dataframe2, left_on = dataframe1_id_name, right_on = dataframe2_id_name)`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jure1V5lbUL3"},"outputs":[],"source":["roster = captains.merge(managers,left_on = 'Id', right_on = 'Id')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKPVydBYbUL3"},"outputs":[],"source":["roster.head(12)"]},{"cell_type":"markdown","metadata":{"id":"LeA6lx6abUL4"},"source":["#### The above python code is equivalent to SQL's\n","```sql\n","SELECT *\n","FROM Captains\n","INNER JOIN Managers\n","ON Captains.Id = Managers.Id\n","```\n","##### ==================================================================================================\n","## Column Renaming\n","\n","We can use the `.rename` function in python to relabel the columns of a dataframe. Suppose we want to rename `Id` to `Cohort` and `Title` to `Captain Rank`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7J2zaBkpbUL4"},"outputs":[],"source":["roster = roster.rename(columns = {\"Id\":\"Cohort\",\"Title\":\"Captain Rank\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXjmFwjCbUL4"},"outputs":[],"source":["roster.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"tCXGWW7-bUL4"},"source":["If we would like to replace all columns, we must use a list of equal length"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZraJ0e_bUL5"},"outputs":[],"source":["roster.columns = ['Cohort Num','Capt Name','Capt Rank','Manager']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03W3qtf1bUL5"},"outputs":[],"source":["roster.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"hus5GlHGbUL5"},"source":["##### ==================================================================================================\n","### Drop Columns\n","The `.drop` function removes specified labels from rows or columns.\n","\n","General Syntax: `df.drop([\"column1\",\"column2\"], axis = \"columns\")`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3sY6K6RbUL5"},"outputs":[],"source":["roster = roster.drop([\"Cohort Num\",\"Capt Rank\"],axis = \"columns\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t5-DixFHbUL5"},"outputs":[],"source":["roster.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"GfosPovRbUL6"},"source":["##### ==================================================================================================\n","### Missing Values / NaN Values\n","\n","There are various types of missing data. Most commonly it could just be data was never collected, the data was handled incorrectly or null valued entry.\n","\n","Missing data can be remedied by the following:\n","1. Removing the row with the missing/NaN values\n","2. Removing the column with the missing/NaN values\n","3. Filling in the missing data\n","\n","For simplicity, we will only focus on the first two methods. The third method can be resolved with value interpolation by use of information from other rows or columns of the dataset. This process requires knowledge outside of the scope of this lesson. There are entire studies dedicated to this topic alone."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHfJBv4JbUL6"},"outputs":[],"source":["cars = pd.read_csv(\"Cars.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCOKnuThbUL6"},"outputs":[],"source":["cars.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"jqfNqfW9bUL6"},"source":["##### ==================================================================================================\n","Now lets sort the companies in alphabetical order"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSaViuSDbUL6"},"outputs":[],"source":["cars = cars.sort_values(\"Company\").reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r61E8BwfbUL7"},"outputs":[],"source":["cars.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"9bn7b9SMbUL7"},"source":["##### ==================================================================================================\n","Now lets check how many entry points are missing. As we can see there are 4 entries in the Location column and 5 entries missing in the Year column by using the `.isna()` function in combination with the `.sum()` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"513awDUibUL7"},"outputs":[],"source":["cars.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"p58o12P2bUL7"},"source":["##### ==================================================================================================\n","Lets inspect all the rows with any missing Loctation entries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gXCggHywbUL7"},"outputs":[],"source":["cars.loc[cars.loc[:, \"Location\"].isna(), :]"]},{"cell_type":"markdown","metadata":{"id":"lGkRs-0gbUL8"},"source":["##### ==================================================================================================\n","Lets inspect all the rows with any missing Year entries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"am48m2rSbUL8"},"outputs":[],"source":["cars.loc[cars.loc[:, \"Year\"].isna(), :]"]},{"cell_type":"markdown","metadata":{"id":"X1UwuM1VbUL8"},"source":["##### ==================================================================================================\n","For simplicity we can fill all the missing Location entries with \"Unknown\"."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OL_nHJKPbUL8"},"outputs":[],"source":["cars.loc[:, \"Location\"] = cars.loc[:, \"Location\"].fillna(value=\"Unknown\")"]},{"cell_type":"markdown","metadata":{"id":"qO2opnkZbUL8"},"source":["##### ==================================================================================================\n","Notice now only rows 9, 29, 35, 37 and 38 contain any `NaN` values in the `Year` column and all entries in the `Location` column is filled in."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fmP3U554bUL8"},"outputs":[],"source":["cars.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"8T0Gv-nAbUL9"},"source":["##### ==================================================================================================\n","Now lets drop **any** rows that include any missing entries. This should remove what was previously rows 9, 29, 35, 37 and 38 and reset the index. This will reduce the number of rows in our dataset from 42 to now 37."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR6qOXzYbUL9"},"outputs":[],"source":["cars = cars.dropna().reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0IPqpBzbUL9"},"outputs":[],"source":["cars.head(-1)"]},{"cell_type":"markdown","metadata":{"id":"MPWvZVS-bUL-"},"source":["##### ==================================================================================================\n","## Summary\n","\n","- `pandas` provides `Series` and `DataFrame` classes that with tabular style data.\n","- `.loc` selects rows and columns based on their column names / labels.\n","- `.iloc` selects rows and columns based on their position / index values.\n","- Calling a DataFrame method with `axis=\"rows\"` or `axis=0` causes it to operate along the row axis.\n","- Calling a DataFrame method with `axis=\"columns\"` or `axis=1` causes it to operate along the columns axis.\n","- `sort_values` reorders rows based on condition\n","- `.rename()` can rename columns in DataFrames. You can also rewrite the `.columns` attribute to rename columns.\n","- `.isna()` detects missing values\n","- `.fillna()` replaces NULL values with a specified value\n","- `.dropna()` removes all rows that contain NULL values\n","- `.merge()` updates content from one DataFrame with content from another Dataframe\n","- `.concat()` combines pandas objects along a particular axis"]},{"cell_type":"markdown","metadata":{"id":"0r098x-8bUL-"},"source":["##### ==================================================================================================\n","### Excercise 1:\n","Create a new DataFrame called `cohort` by inner joining the two DataFrames `roster` and `exam`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0CC4Lk0LbUL-"},"outputs":[],"source":["roster = pd.DataFrame(\n","{\n","    \"Name\" : [\"James\",\"Greg\",\"Patrick\",\"Chris\",\"Cynthia\",\"Chandra\", \"John\",\"David\",\"Tiffany\",\"Peter\"],\n","    \"Id\": [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\n","    \n","})\n","\n","exam = pd.DataFrame({\n","    \"Exam 1\" : [89,78,81,90,93,76,66,87,42,55],\n","    \"Exam 2\" : [100,74,20,86,60,76,92,97,88,90],\n","    \"Exam 3\" : [85,60,90,90,88,76,55,None,64,79],\n","    \"Id\" : [\"4\",\"2\",\"1\",\"7\",\"5\",\"10\",\"6\",\"3\",\"9\",\"8\"]\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXrBerEObUL_"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"zI7Zl7KLbUL_"},"source":["##### ==================================================================================================\n","### Excercise 2:\n","Fill all missing grades with 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIMLLzOZbUL_"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"qh21Q3L1bUL_"},"source":["##### ==================================================================================================\n","### Excercise 3:\n","Update James Exam 2 score from 20 to 85 and update Tiffany Exam 1 score from 42 to 88"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUOCHgh8bUMA"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"yw5AtNiybUMA"},"source":["##### ==================================================================================================\n","### Excercise 4:\n","Create a series called `Average` that takes the average of Exam 1, Exam 2 and Exam 3 scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgfabaYMbUMA"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"M7cnodYgbUMB"},"source":["##### ==================================================================================================\n","### Excercise 5:\n","Incorporate the newly created `Average` column into the DataFrame `cohort`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8GSKM16bUMB"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"ANNddz4LbUMB"},"source":["##### ==================================================================================================\n","### Excercise 6:\n","Sort the dataset by Average in **descending** order and reindex the DataFrame"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cXz9PBmLbUMB"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"Xfi6qvMobUMC"},"source":["##### ==================================================================================================\n","### Excercise 7:\n","Drop columns Exam 1, 2, and 3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNAEcLF5bUMC"},"outputs":[],"source":["# Write your code here"]},{"cell_type":"markdown","metadata":{"id":"_xYr69bobUMC"},"source":["##### ==================================================================================================\n","### Excercise 8:\n","Select only the top 3 **Name, Id and Average only*** based on highest Average grade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1IYz1MBbUMC"},"outputs":[],"source":["# Write your code here"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}